{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image1Text</th>\n",
       "      <th>image2Text</th>\n",
       "      <th>image3Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga780619</td>\n",
       "      <td>hi, there...i'm jon arbuckle. i'm a cartoonist...</td>\n",
       "      <td>hi, there. i'm garfield. i'm a cat, and this i...</td>\n",
       "      <td>our only thought is to entertain you. feed me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ga780620</td>\n",
       "      <td>happy birthday, garfield. i have a surprise fo...</td>\n",
       "      <td>a rubber mousey!</td>\n",
       "      <td>could've used a little salt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ga780621</td>\n",
       "      <td>a mouse! get it!</td>\n",
       "      <td>garfield! you didn't even try!</td>\n",
       "      <td>show me a good mouser, and i'll show you a cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ga780628</td>\n",
       "      <td>here, garfield, ...beg.</td>\n",
       "      <td>eeyouch!!</td>\n",
       "      <td>groveling is not one of my strong suits.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ga780630</td>\n",
       "      <td>all i ever do is eat and sleep, eat and sleep,...</td>\n",
       "      <td>there must be more to a cat's life than that.</td>\n",
       "      <td>but, i hope not.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11741</th>\n",
       "      <td>ga200222</td>\n",
       "      <td>jon doesn't trust me.</td>\n",
       "      <td>what are you up to now?!</td>\n",
       "      <td>all of the fun withot the effort.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11742</th>\n",
       "      <td>ga200224</td>\n",
       "      <td>i am so sleepy...</td>\n",
       "      <td>z</td>\n",
       "      <td>now back to being sleepy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11743</th>\n",
       "      <td>ga200225</td>\n",
       "      <td>ah! oatmeal!</td>\n",
       "      <td>who doesn't like that?</td>\n",
       "      <td>i just patched that crack in the wall.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11744</th>\n",
       "      <td>ga200226</td>\n",
       "      <td>grrr</td>\n",
       "      <td>aaaaaaaaaand...wait for it...</td>\n",
       "      <td>bark! way to build suspense.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11747</th>\n",
       "      <td>ga200229</td>\n",
       "      <td>i'm cute.</td>\n",
       "      <td>and you...well, you're you.</td>\n",
       "      <td>was that a compliment or an insult?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8293 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                         image1Text  \\\n",
       "0      ga780619  hi, there...i'm jon arbuckle. i'm a cartoonist...   \n",
       "1      ga780620  happy birthday, garfield. i have a surprise fo...   \n",
       "2      ga780621                                   a mouse! get it!   \n",
       "8      ga780628                            here, garfield, ...beg.   \n",
       "10     ga780630  all i ever do is eat and sleep, eat and sleep,...   \n",
       "...         ...                                                ...   \n",
       "11741  ga200222                              jon doesn't trust me.   \n",
       "11742  ga200224                                  i am so sleepy...   \n",
       "11743  ga200225                                       ah! oatmeal!   \n",
       "11744  ga200226                                               grrr   \n",
       "11747  ga200229                                          i'm cute.   \n",
       "\n",
       "                                              image2Text  \\\n",
       "0      hi, there. i'm garfield. i'm a cat, and this i...   \n",
       "1                                       a rubber mousey!   \n",
       "2                         garfield! you didn't even try!   \n",
       "8                                              eeyouch!!   \n",
       "10         there must be more to a cat's life than that.   \n",
       "...                                                  ...   \n",
       "11741                           what are you up to now?!   \n",
       "11742                                                  z   \n",
       "11743                             who doesn't like that?   \n",
       "11744                      aaaaaaaaaand...wait for it...   \n",
       "11747                        and you...well, you're you.   \n",
       "\n",
       "                                              image3Text  \n",
       "0         our only thought is to entertain you. feed me.  \n",
       "1                         could've used a little salt...  \n",
       "2      show me a good mouser, and i'll show you a cat...  \n",
       "8               groveling is not one of my strong suits.  \n",
       "10                                      but, i hope not.  \n",
       "...                                                  ...  \n",
       "11741                  all of the fun withot the effort.  \n",
       "11742                          now back to being sleepy.  \n",
       "11743             i just patched that crack in the wall.  \n",
       "11744                       bark! way to build suspense.  \n",
       "11747                was that a compliment or an insult?  \n",
       "\n",
       "[8293 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('garfield.csv')\n",
    "\n",
    "\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "df.drop_duplicates()\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11748"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('garfield.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image1Text</th>\n",
       "      <th>image2Text</th>\n",
       "      <th>image3Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga780619</td>\n",
       "      <td>Hi   there      I  m Jon Arbuckle   I  m a car...</td>\n",
       "      <td>Hi   there   I  m Garfield   I  m a cat   and ...</td>\n",
       "      <td>Our only thought is to entertain you   Feed me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ga780620</td>\n",
       "      <td>Happy birthday   Garfield   I have a surprise ...</td>\n",
       "      <td>A rubber mousey</td>\n",
       "      <td>Could  ve used a little salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ga780621</td>\n",
       "      <td>A MOUSE   GET IT</td>\n",
       "      <td>Garfield   You didn  t even try</td>\n",
       "      <td>Show me a good mouser   and I  ll show you a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga780622</td>\n",
       "      <td>I  m putting you on a diet   Garfield      her...</td>\n",
       "      <td>WHA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ga780623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ahhhhh</td>\n",
       "      <td>Happiness is a warm television set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11743</th>\n",
       "      <td>ga200225</td>\n",
       "      <td>Ah   Oatmeal</td>\n",
       "      <td>Who doesn  t like that</td>\n",
       "      <td>I just patched that crack in the wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11744</th>\n",
       "      <td>ga200226</td>\n",
       "      <td>Grrr</td>\n",
       "      <td>Aaaaaaaaaand      wait for it</td>\n",
       "      <td>BARK   Way to build suspense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11745</th>\n",
       "      <td>ga200227</td>\n",
       "      <td>FLYING ELEPHANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11746</th>\n",
       "      <td>ga200228</td>\n",
       "      <td>Bark   Bark   Bark   Bark   Bark   Bark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon never gets my jokes either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11747</th>\n",
       "      <td>ga200229</td>\n",
       "      <td>I  m cute</td>\n",
       "      <td>And you      well   you  re you</td>\n",
       "      <td>Was that a compliment or an insult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11748 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                         image1Text  \\\n",
       "0      ga780619  Hi   there      I  m Jon Arbuckle   I  m a car...   \n",
       "1      ga780620  Happy birthday   Garfield   I have a surprise ...   \n",
       "2      ga780621                                 A MOUSE   GET IT     \n",
       "3      ga780622  I  m putting you on a diet   Garfield      her...   \n",
       "4      ga780623                                                NaN   \n",
       "...         ...                                                ...   \n",
       "11743  ga200225                                     Ah   Oatmeal     \n",
       "11744  ga200226                                               Grrr   \n",
       "11745  ga200227                                  FLYING ELEPHANT     \n",
       "11746  ga200228          Bark   Bark   Bark   Bark   Bark   Bark     \n",
       "11747  ga200229                                        I  m cute     \n",
       "\n",
       "                                              image2Text  \\\n",
       "0      Hi   there   I  m Garfield   I  m a cat   and ...   \n",
       "1                                      A rubber mousey     \n",
       "2                      Garfield   You didn  t even try     \n",
       "3                                              WHA         \n",
       "4                                           Ahhhhh         \n",
       "...                                                  ...   \n",
       "11743                           Who doesn  t like that     \n",
       "11744                Aaaaaaaaaand      wait for it         \n",
       "11745                                                NaN   \n",
       "11746                                                NaN   \n",
       "11747                  And you      well   you  re you     \n",
       "\n",
       "                                              image3Text  \n",
       "0       Our only thought is to entertain you   Feed me    \n",
       "1                     Could  ve used a little salt        \n",
       "2      Show me a good mouser   and I  ll show you a c...  \n",
       "3                                                    NaN  \n",
       "4                   Happiness is a warm television set    \n",
       "...                                                  ...  \n",
       "11743            I just patched that crack in the wall    \n",
       "11744                     BARK   Way to build suspense    \n",
       "11745                                                NaN  \n",
       "11746                   Jon never gets my jokes either    \n",
       "11747               Was that a compliment or an insult    \n",
       "\n",
       "[11748 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"image1Text\"] = df['image1Text'].str.replace('[^\\w\\s]','  ')\n",
    "df[\"image2Text\"] = df['image2Text'].str.replace('[^\\w\\s]','  ')\n",
    "df[\"image3Text\"] = df['image3Text'].str.replace('[^\\w\\s]','  ')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 11748 characters\n"
     ]
    }
   ],
   "source": [
    "print ('Length of text: {} characters'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sguha/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threePane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi   there      I  m Jon Arbuckle   I  m a car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy birthday   Garfield   I have a surprise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A MOUSE   GET IT   - Garfield   You didn  t ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Here   Garfield         beg   - EEYOUCH     - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>All I ever do is eat and sleep   eat and sleep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11741</th>\n",
       "      <td>Jon doesn  t trust me   - What are you up to n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11742</th>\n",
       "      <td>I am so sleepy       - Z - Now back to being s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11743</th>\n",
       "      <td>Ah   Oatmeal   - Who doesn  t like that   - I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11744</th>\n",
       "      <td>Grrr - Aaaaaaaaaand      wait for it       - B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11747</th>\n",
       "      <td>I  m cute   - And you      well   you  re you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8293 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               threePane\n",
       "0      Hi   there      I  m Jon Arbuckle   I  m a car...\n",
       "1      Happy birthday   Garfield   I have a surprise ...\n",
       "2      A MOUSE   GET IT   - Garfield   You didn  t ev...\n",
       "8      Here   Garfield         beg   - EEYOUCH     - ...\n",
       "10     All I ever do is eat and sleep   eat and sleep...\n",
       "...                                                  ...\n",
       "11741  Jon doesn  t trust me   - What are you up to n...\n",
       "11742  I am so sleepy       - Z - Now back to being s...\n",
       "11743  Ah   Oatmeal   - Who doesn  t like that   - I ...\n",
       "11744  Grrr - Aaaaaaaaaand      wait for it       - B...\n",
       "11747  I  m cute   - And you      well   you  re you ...\n",
       "\n",
       "[8293 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df\n",
    "df2 = df2.dropna()\n",
    "df2['threePane'] = df2['image1Text'] + ' - ' + df2['image2Text'] + ' - ' + df2['image3Text']\n",
    "df2 = df2.drop(['id', 'image1Text', 'image2Text', 'image3Text'], axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image3Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our only thought is to entertain you   Feed me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could  ve used a little salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Show me a good mouser   and I  ll show you a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happiness is a warm television set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ZZZZZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>I  ve heard of catnaps   but this is ridiculou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Whoever thought a nap attack could hurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>There you have it   Garfield  s passion for fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image3Text\n",
       "0    Our only thought is to entertain you   Feed me  \n",
       "1                  Could  ve used a little salt      \n",
       "2   Show me a good mouser   and I  ll show you a c...\n",
       "3                                                 NaN\n",
       "4                Happiness is a warm television set  \n",
       "..                                                ...\n",
       "95                                              ZZZZZ\n",
       "96  I  ve heard of catnaps   but this is ridiculou...\n",
       "97          Whoever thought a nap attack could hurt  \n",
       "98  There you have it   Garfield  s passion for fo...\n",
       "99                                                NaN\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[:100]\n",
    "df = df.drop(['id', 'image1Text', 'image2Text'], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_set = set()\n",
    "word_count = 0\n",
    "all_word_list = []\n",
    "max_phrase_length = float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in df2.iterrows():\n",
    "#     print(row['image3Text'].lower())\n",
    "#     lower_word = row['image3Text'].lower()\n",
    "    lower_word = row['threePane'].lower()\n",
    "    split_word = lower_word.split()\n",
    "    for i, word in enumerate(split_word):\n",
    "        if len(word) == 1 and (word != 'i' and word != 'a' and word != '-'):\n",
    "            continue\n",
    "        word_set.add(word)\n",
    "        word_count += 1\n",
    "        all_word_list.append(word)\n",
    "    max_phrase_length = max(max_phrase_length, len(split_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11613"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_phrase_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-',\n",
       " 'a',\n",
       " 'aarrrgh',\n",
       " 'about',\n",
       " 'active',\n",
       " 'afternoons',\n",
       " 'all',\n",
       " 'almira',\n",
       " 'amazon',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'anxiety',\n",
       " 'anything',\n",
       " 'arbuckle',\n",
       " 'are',\n",
       " 'arm',\n",
       " 'arrogant',\n",
       " 'as',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'attack',\n",
       " 'attacks',\n",
       " 'average',\n",
       " 'away',\n",
       " 'bachelor',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'banned',\n",
       " 'bark',\n",
       " 'bathroom',\n",
       " 'bbbbb',\n",
       " 'be',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'been',\n",
       " 'beg',\n",
       " 'beliefs',\n",
       " 'believe',\n",
       " 'better',\n",
       " 'biff',\n",
       " 'big',\n",
       " 'bijou',\n",
       " 'birthday',\n",
       " 'bite',\n",
       " 'bleak',\n",
       " 'bleeding',\n",
       " 'bless',\n",
       " 'blimp',\n",
       " 'blood',\n",
       " 'boing',\n",
       " 'bop',\n",
       " 'bouquet',\n",
       " 'boy',\n",
       " 'breakfast',\n",
       " 'breath',\n",
       " 'briquettes',\n",
       " 'bugs',\n",
       " 'but',\n",
       " 'buzzzzz',\n",
       " 'by',\n",
       " 'car',\n",
       " 'cartoonist',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catnaps',\n",
       " 'cats',\n",
       " 'celebrate',\n",
       " 'centerfold',\n",
       " 'chair',\n",
       " 'chicken',\n",
       " 'chunk',\n",
       " 'claws',\n",
       " 'click',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'comes',\n",
       " 'conservation',\n",
       " 'conserve',\n",
       " 'content',\n",
       " 'control',\n",
       " 'cookout',\n",
       " 'corn',\n",
       " 'could',\n",
       " 'country',\n",
       " 'crash',\n",
       " 'crazy',\n",
       " 'crick',\n",
       " 'curdled',\n",
       " 'cut',\n",
       " 'dab',\n",
       " 'darn',\n",
       " 'day',\n",
       " 'deal',\n",
       " 'declawed',\n",
       " 'desired',\n",
       " 'devil',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'die',\n",
       " 'diet',\n",
       " 'do',\n",
       " 'doctor',\n",
       " 'dog',\n",
       " 'dogs',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'down',\n",
       " 'dumb',\n",
       " 'eat',\n",
       " 'edsel',\n",
       " 'eeyouch',\n",
       " 'elke',\n",
       " 'energy',\n",
       " 'enjoy',\n",
       " 'entertain',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'exactly',\n",
       " 'exceeded',\n",
       " 'excuuuuuuse',\n",
       " 'exercise',\n",
       " 'expecting',\n",
       " 'farrah',\n",
       " 'fat',\n",
       " 'favorite',\n",
       " 'feed',\n",
       " 'fever',\n",
       " 'find',\n",
       " 'fire',\n",
       " 'flick',\n",
       " 'floor',\n",
       " 'food',\n",
       " 'football',\n",
       " 'for',\n",
       " 'freezing',\n",
       " 'fresh',\n",
       " 'frightening',\n",
       " 'from',\n",
       " 'fump',\n",
       " 'fun',\n",
       " 'garfield',\n",
       " 'gas',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'go',\n",
       " 'god',\n",
       " 'going',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'got',\n",
       " 'gotta',\n",
       " 'groveling',\n",
       " 'had',\n",
       " 'happy',\n",
       " 'has',\n",
       " 'hate',\n",
       " 'have',\n",
       " 'having',\n",
       " 'hay',\n",
       " 'he',\n",
       " 'head',\n",
       " 'heard',\n",
       " 'heat',\n",
       " 'heh',\n",
       " 'hello',\n",
       " 'here',\n",
       " 'hi',\n",
       " 'him',\n",
       " 'hindenburg',\n",
       " 'hire',\n",
       " 'his',\n",
       " 'hope',\n",
       " 'how',\n",
       " 'hurt',\n",
       " 'hydrants',\n",
       " 'i',\n",
       " 'icy',\n",
       " 'idea',\n",
       " 'if',\n",
       " 'in',\n",
       " 'instance',\n",
       " 'intended',\n",
       " 'is',\n",
       " 'it',\n",
       " 'itch',\n",
       " 'jerk',\n",
       " 'jon',\n",
       " 'just',\n",
       " 'kaboing',\n",
       " 'keep',\n",
       " 'kid',\n",
       " 'kitty',\n",
       " 'know',\n",
       " 'labor',\n",
       " 'lasagna',\n",
       " 'last',\n",
       " 'lawns',\n",
       " 'lawsey',\n",
       " 'lazy',\n",
       " 'learn',\n",
       " 'least',\n",
       " 'leaves',\n",
       " 'leg',\n",
       " 'let',\n",
       " 'life',\n",
       " 'lifeless',\n",
       " 'like',\n",
       " 'little',\n",
       " 'll',\n",
       " 'look',\n",
       " 'looks',\n",
       " 'love',\n",
       " 'low',\n",
       " 'lyman',\n",
       " 'made',\n",
       " 'magazine',\n",
       " 'mark',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'mention',\n",
       " 'might',\n",
       " 'mind',\n",
       " 'minute',\n",
       " 'mondays',\n",
       " 'more',\n",
       " 'morning',\n",
       " 'most',\n",
       " 'mouse',\n",
       " 'mouser',\n",
       " 'mousey',\n",
       " 'movies',\n",
       " 'much',\n",
       " 'munch',\n",
       " 'munchies',\n",
       " 'must',\n",
       " 'my',\n",
       " 'mystery',\n",
       " 'name',\n",
       " 'named',\n",
       " 'nap',\n",
       " 'nation',\n",
       " 'nature',\n",
       " 'needed',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'night',\n",
       " 'no',\n",
       " 'noisy',\n",
       " 'not',\n",
       " 'notice',\n",
       " 'november',\n",
       " 'now',\n",
       " 'odie',\n",
       " 'of',\n",
       " 'oh',\n",
       " 'on',\n",
       " 'one',\n",
       " 'only',\n",
       " 'oops',\n",
       " 'ordinary',\n",
       " 'our',\n",
       " 'out',\n",
       " 'oven',\n",
       " 'part',\n",
       " 'passion',\n",
       " 'pat',\n",
       " 'pate',\n",
       " 'people',\n",
       " 'perfect',\n",
       " 'pet',\n",
       " 'pick',\n",
       " 'pig',\n",
       " 'places',\n",
       " 'play',\n",
       " 'played',\n",
       " 'playing',\n",
       " 'plot',\n",
       " 'poke',\n",
       " 'poomp',\n",
       " 'poor',\n",
       " 'post',\n",
       " 'punt',\n",
       " 'purrr',\n",
       " 'purrrr',\n",
       " 'puts',\n",
       " 'putting',\n",
       " 'raw',\n",
       " 're',\n",
       " 'really',\n",
       " 'removing',\n",
       " 'ridiculous',\n",
       " 'risk',\n",
       " 'roots',\n",
       " 'roughed',\n",
       " 'rrrr',\n",
       " 'rubber',\n",
       " 'rude',\n",
       " 'rusting',\n",
       " 'salt',\n",
       " 'sandboxes',\n",
       " 'saturday',\n",
       " 'scale',\n",
       " 'scorched',\n",
       " 'scratch',\n",
       " 'scratching',\n",
       " 'season',\n",
       " 'seats',\n",
       " 'see',\n",
       " 'send',\n",
       " 'set',\n",
       " 'she',\n",
       " 'ship',\n",
       " 'shmabor',\n",
       " 'should',\n",
       " 'show',\n",
       " 'shred',\n",
       " 'silly',\n",
       " 'sits',\n",
       " 'sitting',\n",
       " 'sleep',\n",
       " 'sloppy',\n",
       " 'slurp',\n",
       " 'smack',\n",
       " 'snapped',\n",
       " 'sniff',\n",
       " 'so',\n",
       " 'some',\n",
       " 'someday',\n",
       " 'somehow',\n",
       " 'something',\n",
       " 'sorry',\n",
       " 'soup',\n",
       " 'spare',\n",
       " 'splash',\n",
       " 'splat',\n",
       " 'spot',\n",
       " 'squirt',\n",
       " 'steak',\n",
       " 'stick',\n",
       " 'sticky',\n",
       " 'still',\n",
       " 'stitches',\n",
       " 'store',\n",
       " 'strength',\n",
       " 'stretch',\n",
       " 'strong',\n",
       " 'stuck',\n",
       " 'sucker',\n",
       " 'suitcase',\n",
       " 'suite',\n",
       " 'suits',\n",
       " 'summer',\n",
       " 'suppose',\n",
       " 'sure',\n",
       " 'surprise',\n",
       " 'swat',\n",
       " 'tack',\n",
       " 'take',\n",
       " 'talking',\n",
       " 'teacher',\n",
       " 'temper',\n",
       " 'than',\n",
       " 'thanks',\n",
       " 'that',\n",
       " 'the',\n",
       " 'theater',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'they',\n",
       " 'think',\n",
       " 'this',\n",
       " 'thought',\n",
       " 'through',\n",
       " 'thursday',\n",
       " 'titanic',\n",
       " 'to',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'trees',\n",
       " 'tried',\n",
       " 'try',\n",
       " 'tuna',\n",
       " 'unarmed',\n",
       " 'unbearable',\n",
       " 'unnecessarily',\n",
       " 'up',\n",
       " 'use',\n",
       " 'used',\n",
       " 've',\n",
       " 'vet',\n",
       " 'watch',\n",
       " 'water',\n",
       " 'way',\n",
       " 'we',\n",
       " 'week',\n",
       " 'well',\n",
       " 'whap',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'whew',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'winds',\n",
       " 'with',\n",
       " 'won',\n",
       " 'wonder',\n",
       " 'woof',\n",
       " 'work',\n",
       " 'would',\n",
       " 'yawn',\n",
       " 'yip',\n",
       " 'you',\n",
       " 'your',\n",
       " 'zzzz',\n",
       " 'zzzzz',\n",
       " 'zzzzzzzz'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "# create mapping of unique words to integers\n",
    "words = sorted(list(word_set))\n",
    "word_to_int = dict((w, i) for i, w in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-': 0,\n",
       " '00': 1,\n",
       " '000': 2,\n",
       " '10': 3,\n",
       " '100': 4,\n",
       " '1001': 5,\n",
       " '100th': 6,\n",
       " '11': 7,\n",
       " '11th': 8,\n",
       " '12': 9,\n",
       " '121': 10,\n",
       " '12th': 11,\n",
       " '13th': 12,\n",
       " '14': 13,\n",
       " '1400': 14,\n",
       " '149': 15,\n",
       " '15': 16,\n",
       " '16': 17,\n",
       " '17': 18,\n",
       " '172': 19,\n",
       " '18': 20,\n",
       " '19': 21,\n",
       " '190': 22,\n",
       " '1922': 23,\n",
       " '1957': 24,\n",
       " '1978': 25,\n",
       " '198': 26,\n",
       " '1981': 27,\n",
       " '1987': 28,\n",
       " '199': 29,\n",
       " '1994': 30,\n",
       " '20': 31,\n",
       " '200': 32,\n",
       " '2014': 33,\n",
       " '20th': 34,\n",
       " '21': 35,\n",
       " '219': 36,\n",
       " '21st': 37,\n",
       " '22': 38,\n",
       " '2254': 39,\n",
       " '23': 40,\n",
       " '238': 41,\n",
       " '24': 42,\n",
       " '25': 43,\n",
       " '250': 44,\n",
       " '25th': 45,\n",
       " '26': 46,\n",
       " '27': 47,\n",
       " '270': 48,\n",
       " '27th': 49,\n",
       " '29': 50,\n",
       " '29th': 51,\n",
       " '2ish': 52,\n",
       " '30': 53,\n",
       " '300': 54,\n",
       " '3000': 55,\n",
       " '31': 56,\n",
       " '313': 57,\n",
       " '32': 58,\n",
       " '342': 59,\n",
       " '35': 60,\n",
       " '350': 61,\n",
       " '36': 62,\n",
       " '364': 63,\n",
       " '365': 64,\n",
       " '39': 65,\n",
       " '40': 66,\n",
       " '400': 67,\n",
       " '41': 68,\n",
       " '42': 69,\n",
       " '43': 70,\n",
       " '432': 71,\n",
       " '44': 72,\n",
       " '45': 73,\n",
       " '48': 74,\n",
       " '499': 75,\n",
       " '50': 76,\n",
       " '500': 77,\n",
       " '532': 78,\n",
       " '57': 79,\n",
       " '59': 80,\n",
       " '5c': 81,\n",
       " '60': 82,\n",
       " '600': 83,\n",
       " '62': 84,\n",
       " '637': 85,\n",
       " '700': 86,\n",
       " '711': 87,\n",
       " '72': 88,\n",
       " '73': 89,\n",
       " '732': 90,\n",
       " '743': 91,\n",
       " '744': 92,\n",
       " '747': 93,\n",
       " '78': 94,\n",
       " '79': 95,\n",
       " '797': 96,\n",
       " '800': 97,\n",
       " '81': 98,\n",
       " '82': 99,\n",
       " '822': 100,\n",
       " '83': 101,\n",
       " '86': 102,\n",
       " '87': 103,\n",
       " '88': 104,\n",
       " '887': 105,\n",
       " '888': 106,\n",
       " '889': 107,\n",
       " '89': 108,\n",
       " '890': 109,\n",
       " '90': 110,\n",
       " '900': 111,\n",
       " 'a': 112,\n",
       " 'aa': 113,\n",
       " 'aaaaaaaaaaaaa': 114,\n",
       " 'aaaaaaaaaand': 115,\n",
       " 'aaaaaaaaahhhh': 116,\n",
       " 'aaaaaaaaants': 117,\n",
       " 'aaaaaaaggghhhhh': 118,\n",
       " 'aaaaah': 119,\n",
       " 'aaaaahhhhhh': 120,\n",
       " 'aaaaggghhh': 121,\n",
       " 'aaaagghhh': 122,\n",
       " 'aaaahhh': 123,\n",
       " 'aaaahhhh': 124,\n",
       " 'aaaand': 125,\n",
       " 'aaaarooooooo': 126,\n",
       " 'aaaarrrgghh': 127,\n",
       " 'aaaarrrgghhh': 128,\n",
       " 'aaagghh': 129,\n",
       " 'aaagh': 130,\n",
       " 'aaah': 131,\n",
       " 'aaahh': 132,\n",
       " 'aaahhh': 133,\n",
       " 'aaand': 134,\n",
       " 'aaargh': 135,\n",
       " 'aaarrrggh': 136,\n",
       " 'aaarrroooo': 137,\n",
       " 'aaayieeee': 138,\n",
       " 'aaeeeeerrrrrrggghhh': 139,\n",
       " 'aaeeeeerrrrrrrggghhh': 140,\n",
       " 'aahhh': 141,\n",
       " 'aaoooogah': 142,\n",
       " 'aardvark': 143,\n",
       " 'aarrrgh': 144,\n",
       " 'aarrrghh': 145,\n",
       " 'aarrrrrggghh': 146,\n",
       " 'abandoned': 147,\n",
       " 'abducted': 148,\n",
       " 'abductions': 149,\n",
       " 'ability': 150,\n",
       " 'able': 151,\n",
       " 'aboard': 152,\n",
       " 'abomination': 153,\n",
       " 'abot': 154,\n",
       " 'abou': 155,\n",
       " 'about': 156,\n",
       " 'abouuuut': 157,\n",
       " 'above': 158,\n",
       " 'abrasions': 159,\n",
       " 'abruptly': 160,\n",
       " 'absolute': 161,\n",
       " 'absolutely': 162,\n",
       " 'absolutes': 163,\n",
       " 'absorbent': 164,\n",
       " 'abu': 165,\n",
       " 'abuse': 166,\n",
       " 'abusing': 167,\n",
       " 'abyssinian': 168,\n",
       " 'ac': 169,\n",
       " 'academy': 170,\n",
       " 'accent': 171,\n",
       " 'accentuate': 172,\n",
       " 'accept': 173,\n",
       " 'acceptable': 174,\n",
       " 'acceptance': 175,\n",
       " 'accepting': 176,\n",
       " 'accessories': 177,\n",
       " 'accident': 178,\n",
       " 'accidentally': 179,\n",
       " 'accompanied': 180,\n",
       " 'accomplish': 181,\n",
       " 'accomplished': 182,\n",
       " 'accomplishments': 183,\n",
       " 'accor': 184,\n",
       " 'accorded': 185,\n",
       " 'accordeon': 186,\n",
       " 'according': 187,\n",
       " 'accordio': 188,\n",
       " 'accordion': 189,\n",
       " 'accordions': 190,\n",
       " 'accosted': 191,\n",
       " 'account': 192,\n",
       " 'accountant': 193,\n",
       " 'accounting': 194,\n",
       " 'accried': 195,\n",
       " 'accrual': 196,\n",
       " 'accuesd': 197,\n",
       " 'accurate': 198,\n",
       " 'accusations': 199,\n",
       " 'ace': 200,\n",
       " 'acetylene': 201,\n",
       " 'ache': 202,\n",
       " 'achieve': 203,\n",
       " 'achievement': 204,\n",
       " 'achoo': 205,\n",
       " 'achy': 206,\n",
       " 'acid': 207,\n",
       " 'ack': 208,\n",
       " 'acknowledged': 209,\n",
       " 'acknowledgement': 210,\n",
       " 'acne': 211,\n",
       " 'acorns': 212,\n",
       " 'acoustics': 213,\n",
       " 'acquaintance': 214,\n",
       " 'acquired': 215,\n",
       " 'acquisition': 216,\n",
       " 'acratch': 217,\n",
       " 'acre': 218,\n",
       " 'acreage': 219,\n",
       " 'acres': 220,\n",
       " 'across': 221,\n",
       " 'act': 222,\n",
       " 'acting': 223,\n",
       " 'action': 224,\n",
       " 'active': 225,\n",
       " 'actor': 226,\n",
       " 'acttive': 227,\n",
       " 'actual': 228,\n",
       " 'actually': 229,\n",
       " 'ad': 230,\n",
       " 'adapt': 231,\n",
       " 'add': 232,\n",
       " 'added': 233,\n",
       " 'adding': 234,\n",
       " 'address': 235,\n",
       " 'addressed': 236,\n",
       " 'addressing': 237,\n",
       " 'adeewong': 238,\n",
       " 'adhesive': 239,\n",
       " 'adjective': 240,\n",
       " 'adjectives': 241,\n",
       " 'adjourned': 242,\n",
       " 'adjust': 243,\n",
       " 'adjusting': 244,\n",
       " 'administration': 245,\n",
       " 'admire': 246,\n",
       " 'admired': 247,\n",
       " 'admirer': 248,\n",
       " 'admires': 249,\n",
       " 'admission': 250,\n",
       " 'admit': 251,\n",
       " 'adn': 252,\n",
       " 'adolescence': 253,\n",
       " 'adopted': 254,\n",
       " 'adorable': 255,\n",
       " 'adore': 256,\n",
       " 'adulation': 257,\n",
       " 'adult': 258,\n",
       " 'advance': 259,\n",
       " 'advanced': 260,\n",
       " 'advances': 261,\n",
       " 'adventure': 262,\n",
       " 'adventures': 263,\n",
       " 'adventurous': 264,\n",
       " 'advertised': 265,\n",
       " 'advertising': 266,\n",
       " 'advice': 267,\n",
       " 'advised': 268,\n",
       " 'aerobics': 269,\n",
       " 'affable': 270,\n",
       " 'affairs': 271,\n",
       " 'affected': 272,\n",
       " 'affection': 273,\n",
       " 'affectionate': 274,\n",
       " 'afford': 275,\n",
       " 'afoot': 276,\n",
       " 'afraid': 277,\n",
       " 'african': 278,\n",
       " 'afte': 279,\n",
       " 'after': 280,\n",
       " 'afterburners': 281,\n",
       " 'afternoon': 282,\n",
       " 'afternoons': 283,\n",
       " 'aftershave': 284,\n",
       " 'afterward': 285,\n",
       " 'again': 286,\n",
       " 'agains': 287,\n",
       " 'against': 288,\n",
       " 'age': 289,\n",
       " 'agenda': 290,\n",
       " 'agent': 291,\n",
       " 'aggravating': 292,\n",
       " 'aging': 293,\n",
       " 'agnes': 294,\n",
       " 'ago': 295,\n",
       " 'agoodpot': 296,\n",
       " 'agree': 297,\n",
       " 'agreed': 298,\n",
       " 'agreement': 299,\n",
       " 'agrees': 300,\n",
       " 'ah': 301,\n",
       " 'aha': 302,\n",
       " 'ahchoo': 303,\n",
       " 'ahead': 304,\n",
       " 'ahem': 305,\n",
       " 'ahh': 306,\n",
       " 'ahha': 307,\n",
       " 'ahhh': 308,\n",
       " 'ahhhh': 309,\n",
       " 'ahhhhh': 310,\n",
       " 'ahhhhhhh': 311,\n",
       " 'ahhhhhhhh': 312,\n",
       " 'ahn': 313,\n",
       " 'aid': 314,\n",
       " 'aids': 315,\n",
       " 'aieee': 316,\n",
       " 'aieeee': 317,\n",
       " 'aieeeeeeee': 318,\n",
       " 'aiiieeeee': 319,\n",
       " 'aiiiiyyyee': 320,\n",
       " 'aiiiyyyeeee': 321,\n",
       " 'aiiiyyyeeeeee': 322,\n",
       " 'aim': 323,\n",
       " 'aims': 324,\n",
       " 'ain': 325,\n",
       " 'air': 326,\n",
       " 'airbags': 327,\n",
       " 'airline': 328,\n",
       " 'airliner': 329,\n",
       " 'airmail': 330,\n",
       " 'airplane': 331,\n",
       " 'airport': 332,\n",
       " 'aisle': 333,\n",
       " 'aiyeee': 334,\n",
       " 'akey': 335,\n",
       " 'al': 336,\n",
       " 'alarm': 337,\n",
       " 'alarms': 338,\n",
       " 'alas': 339,\n",
       " 'alaskan': 340,\n",
       " 'albacore': 341,\n",
       " 'albeit': 342,\n",
       " 'albino': 343,\n",
       " 'albinos': 344,\n",
       " 'album': 345,\n",
       " 'aleck': 346,\n",
       " 'alert': 347,\n",
       " 'alerting': 348,\n",
       " 'alfresco': 349,\n",
       " 'alibi': 350,\n",
       " 'alien': 351,\n",
       " 'alienate': 352,\n",
       " 'alienated': 353,\n",
       " 'aliens': 354,\n",
       " 'alike': 355,\n",
       " 'alineated': 356,\n",
       " 'alittle': 357,\n",
       " 'alive': 358,\n",
       " 'all': 359,\n",
       " 'allclear': 360,\n",
       " 'allergic': 361,\n",
       " 'allergy': 362,\n",
       " 'alley': 363,\n",
       " 'alli': 364,\n",
       " 'alligator': 365,\n",
       " 'alliteration': 366,\n",
       " 'allow': 367,\n",
       " 'allowed': 368,\n",
       " 'allowing': 369,\n",
       " 'allows': 370,\n",
       " 'almira': 371,\n",
       " 'almost': 372,\n",
       " 'aloe': 373,\n",
       " 'aloha': 374,\n",
       " 'alone': 375,\n",
       " 'along': 376,\n",
       " 'alongwithmore': 377,\n",
       " 'already': 378,\n",
       " 'alrene': 379,\n",
       " 'alright': 380,\n",
       " 'alriiiight': 381,\n",
       " 'alriiiiight': 382,\n",
       " 'also': 383,\n",
       " 'alter': 384,\n",
       " 'alternative': 385,\n",
       " 'although': 386,\n",
       " 'altitude': 387,\n",
       " 'aluminium': 388,\n",
       " 'always': 389,\n",
       " 'am': 390,\n",
       " 'ama': 391,\n",
       " 'amanda': 392,\n",
       " 'amateur': 393,\n",
       " 'amateurs': 394,\n",
       " 'amaze': 395,\n",
       " 'amazing': 396,\n",
       " 'amazingly': 397,\n",
       " 'amazon': 398,\n",
       " 'amazonian': 399,\n",
       " 'ambition': 400,\n",
       " 'ambitious': 401,\n",
       " 'ambled': 402,\n",
       " 'ambulance': 403,\n",
       " 'ambush': 404,\n",
       " 'amen': 405,\n",
       " 'amends': 406,\n",
       " 'amenities': 407,\n",
       " 'america': 408,\n",
       " 'americain': 409,\n",
       " 'american': 410,\n",
       " 'ammo': 411,\n",
       " 'amnesia': 412,\n",
       " 'amoeba': 413,\n",
       " 'among': 414,\n",
       " 'amount': 415,\n",
       " 'amputate': 416,\n",
       " 'amuse': 417,\n",
       " 'amused': 418,\n",
       " 'amusement': 419,\n",
       " 'an': 420,\n",
       " 'analogies': 421,\n",
       " 'ancestors': 422,\n",
       " 'anchovies': 423,\n",
       " 'ancient': 424,\n",
       " 'and': 425,\n",
       " 'andmaybea': 426,\n",
       " 'anectdotes': 427,\n",
       " 'anesthetic': 428,\n",
       " 'anew': 429,\n",
       " 'anf': 430,\n",
       " 'angel': 431,\n",
       " 'angelic': 432,\n",
       " 'angels': 433,\n",
       " 'anger': 434,\n",
       " 'angle': 435,\n",
       " 'angora': 436,\n",
       " 'angry': 437,\n",
       " 'angy': 438,\n",
       " 'anicehotcup': 439,\n",
       " 'animal': 440,\n",
       " 'animals': 441,\n",
       " 'anincredible': 442,\n",
       " 'ankles': 443,\n",
       " 'anmesia': 444,\n",
       " 'ann': 445,\n",
       " 'anniversary': 446,\n",
       " 'annnd': 447,\n",
       " 'annnnnd': 448,\n",
       " 'announcement': 449,\n",
       " 'annoy': 450,\n",
       " 'annoyed': 451,\n",
       " 'annoying': 452,\n",
       " 'annoys': 453,\n",
       " 'annual': 454,\n",
       " 'anonymous': 455,\n",
       " 'anothe': 456,\n",
       " 'another': 457,\n",
       " 'ans': 458,\n",
       " 'anser': 459,\n",
       " 'answer': 460,\n",
       " 'answered': 461,\n",
       " 'answering': 462,\n",
       " 'answers': 463,\n",
       " 'ant': 464,\n",
       " 'antacid': 465,\n",
       " 'antenna': 466,\n",
       " 'anthem': 467,\n",
       " 'anthill': 468,\n",
       " 'anthrax': 469,\n",
       " 'anticipate': 470,\n",
       " 'anticipation': 471,\n",
       " 'antidote': 472,\n",
       " 'antique': 473,\n",
       " 'antler': 474,\n",
       " 'ants': 475,\n",
       " 'anvewope': 476,\n",
       " 'anvil': 477,\n",
       " 'anxiety': 478,\n",
       " 'any': 479,\n",
       " 'anybody': 480,\n",
       " 'anyhting': 481,\n",
       " 'anymore': 482,\n",
       " 'anyone': 483,\n",
       " 'anything': 484,\n",
       " 'anytime': 485,\n",
       " 'anyway': 486,\n",
       " 'anywhere': 487,\n",
       " 'apart': 488,\n",
       " 'apartment': 489,\n",
       " 'apathetic': 490,\n",
       " 'apathy': 491,\n",
       " 'apes': 492,\n",
       " 'aphrodite': 493,\n",
       " 'apie': 494,\n",
       " 'apologies': 495,\n",
       " 'apologize': 496,\n",
       " 'apology': 497,\n",
       " 'apparel': 498,\n",
       " 'apparent': 499,\n",
       " 'apparently': 500,\n",
       " 'appeal': 501,\n",
       " 'appealing': 502,\n",
       " 'appear': 503,\n",
       " 'appearance': 504,\n",
       " 'appearances': 505,\n",
       " 'appeared': 506,\n",
       " 'appearing': 507,\n",
       " 'appears': 508,\n",
       " 'appetit': 509,\n",
       " 'appetite': 510,\n",
       " 'appetizer': 511,\n",
       " 'appl': 512,\n",
       " 'applause': 513,\n",
       " 'apple': 514,\n",
       " 'apples': 515,\n",
       " 'appliances': 516,\n",
       " 'applications': 517,\n",
       " 'applied': 518,\n",
       " 'apply': 519,\n",
       " 'appoint': 520,\n",
       " 'appointed': 521,\n",
       " 'appointment': 522,\n",
       " 'appreciate': 523,\n",
       " 'appreciated': 524,\n",
       " 'appreciates': 525,\n",
       " 'appreciation': 526,\n",
       " 'approach': 527,\n",
       " 'approaches': 528,\n",
       " 'approaching': 529,\n",
       " 'appropriate': 530,\n",
       " 'appropriately': 531,\n",
       " 'approved': 532,\n",
       " 'april': 533,\n",
       " 'apron': 534,\n",
       " 'aquarium': 535,\n",
       " 'aquatic': 536,\n",
       " 'ar': 537,\n",
       " 'arachnid': 538,\n",
       " 'araound': 539,\n",
       " 'arbu': 540,\n",
       " 'arbuckel': 541,\n",
       " 'arbuckle': 542,\n",
       " 'archaeologist': 543,\n",
       " 'archenemy': 544,\n",
       " 'arches': 545,\n",
       " 'archrival': 546,\n",
       " 'are': 547,\n",
       " 'area': 548,\n",
       " 'aren': 549,\n",
       " 'areplenty': 550,\n",
       " 'arf': 551,\n",
       " 'argue': 552,\n",
       " 'argument': 553,\n",
       " 'argumentative': 554,\n",
       " 'arise': 555,\n",
       " 'aristocratic': 556,\n",
       " 'aristotelean': 557,\n",
       " 'arlene': 558,\n",
       " 'arm': 559,\n",
       " 'armando': 560,\n",
       " 'armchair': 561,\n",
       " 'armed': 562,\n",
       " 'armholes': 563,\n",
       " 'armor': 564,\n",
       " 'armpit': 565,\n",
       " 'armpits': 566,\n",
       " 'arms': 567,\n",
       " 'army': 568,\n",
       " 'arno': 569,\n",
       " 'aroma': 570,\n",
       " 'arooo': 571,\n",
       " 'aroooo': 572,\n",
       " 'arooooo': 573,\n",
       " 'aroooooo': 574,\n",
       " 'arooooooo': 575,\n",
       " 'aroooooooo': 576,\n",
       " 'aroooooooooo': 577,\n",
       " 'aroooooooooooo': 578,\n",
       " 'arose': 579,\n",
       " 'around': 580,\n",
       " 'arr': 581,\n",
       " 'arranged': 582,\n",
       " 'arrangements': 583,\n",
       " 'arrest': 584,\n",
       " 'arrested': 585,\n",
       " 'arrgh': 586,\n",
       " 'arrive': 587,\n",
       " 'arrived': 588,\n",
       " 'arriving': 589,\n",
       " 'arrogant': 590,\n",
       " 'arrow': 591,\n",
       " 'arrowhead': 592,\n",
       " 'arrows': 593,\n",
       " 'arrrgghhh': 594,\n",
       " 'arrrgh': 595,\n",
       " 'arrrghh': 596,\n",
       " 'arrroooo': 597,\n",
       " 'arrrrgh': 598,\n",
       " 'arrrrrgh': 599,\n",
       " 'arrrrrooooooooo': 600,\n",
       " 'arrrrrrgh': 601,\n",
       " 'arrrrrrrgh': 602,\n",
       " 'art': 603,\n",
       " 'article': 604,\n",
       " 'artificial': 605,\n",
       " 'artist': 606,\n",
       " 'artistic': 607,\n",
       " 'artists': 608,\n",
       " 'arts': 609,\n",
       " 'as': 610,\n",
       " 'ascot': 611,\n",
       " 'asecondandthird': 612,\n",
       " 'ash': 613,\n",
       " 'ashamed': 614,\n",
       " 'ashes': 615,\n",
       " 'aside': 616,\n",
       " 'ask': 617,\n",
       " 'aske': 618,\n",
       " 'asked': 619,\n",
       " 'asking': 620,\n",
       " 'asks': 621,\n",
       " 'asleep': 622,\n",
       " 'aspire': 623,\n",
       " 'aspirin': 624,\n",
       " 'assault': 625,\n",
       " 'assemblage': 626,\n",
       " 'assembling': 627,\n",
       " 'assembly': 628,\n",
       " 'assertive': 629,\n",
       " 'assess': 630,\n",
       " 'assessing': 631,\n",
       " 'assistance': 632,\n",
       " 'assistant': 633,\n",
       " 'associate': 634,\n",
       " 'association': 635,\n",
       " 'assume': 636,\n",
       " 'assumed': 637,\n",
       " 'assumes': 638,\n",
       " 'assuming': 639,\n",
       " 'assumption': 640,\n",
       " 'astronauts': 641,\n",
       " 'at': 642,\n",
       " 'atay': 643,\n",
       " 'ate': 644,\n",
       " 'athletic': 645,\n",
       " 'athletics': 646,\n",
       " 'atlantic': 647,\n",
       " 'atop': 648,\n",
       " 'atrophy': 649,\n",
       " 'atta': 650,\n",
       " 'attaboy': 651,\n",
       " 'attached': 652,\n",
       " 'attack': 653,\n",
       " 'attacked': 654,\n",
       " 'attacking': 655,\n",
       " 'attacks': 656,\n",
       " 'attempt': 657,\n",
       " 'attention': 658,\n",
       " 'attic': 659,\n",
       " 'attila': 660,\n",
       " 'attire': 661,\n",
       " 'attitude': 662,\n",
       " 'attorney': 663,\n",
       " 'attract': 664,\n",
       " 'attracted': 665,\n",
       " 'attracting': 666,\n",
       " 'attraction': 667,\n",
       " 'attractive': 668,\n",
       " 'attribute': 669,\n",
       " 'attributes': 670,\n",
       " 'au': 671,\n",
       " 'auction': 672,\n",
       " 'audience': 673,\n",
       " 'audition': 674,\n",
       " 'aunt': 675,\n",
       " 'auspicious': 676,\n",
       " 'aussie': 677,\n",
       " 'australia': 678,\n",
       " 'authorities': 679,\n",
       " 'authority': 680,\n",
       " 'autobiographies': 681,\n",
       " 'autobiography': 682,\n",
       " 'autograph': 683,\n",
       " 'autographing': 684,\n",
       " 'automatic': 685,\n",
       " 'autumn': 686,\n",
       " 'auugh': 687,\n",
       " 'auwl': 688,\n",
       " 'available': 689,\n",
       " 'avanger': 690,\n",
       " 'ave': 691,\n",
       " 'avec': 692,\n",
       " 'avenger': 693,\n",
       " 'avengers': 694,\n",
       " 'avenging': 695,\n",
       " 'avenue': 696,\n",
       " 'average': 697,\n",
       " 'averages': 698,\n",
       " 'averaging': 699,\n",
       " 'avert': 700,\n",
       " 'avocado': 701,\n",
       " 'avoid': 702,\n",
       " 'avoided': 703,\n",
       " 'avoiding': 704,\n",
       " 'aw': 705,\n",
       " 'awaits': 706,\n",
       " 'awake': 707,\n",
       " 'awaken': 708,\n",
       " 'awakened': 709,\n",
       " 'awakening': 710,\n",
       " 'awakens': 711,\n",
       " 'awakes': 712,\n",
       " 'award': 713,\n",
       " 'awards': 714,\n",
       " 'aware': 715,\n",
       " 'away': 716,\n",
       " 'awesome': 717,\n",
       " 'awful': 718,\n",
       " 'awhile': 719,\n",
       " 'awk': 720,\n",
       " 'awkward': 721,\n",
       " 'awoke': 722,\n",
       " 'awrk': 723,\n",
       " 'awrm': 724,\n",
       " 'aww': 725,\n",
       " 'awww': 726,\n",
       " 'awwwk': 727,\n",
       " 'awwww': 728,\n",
       " 'awwwww': 729,\n",
       " 'awwwwwwwwww': 730,\n",
       " 'ayieee': 731,\n",
       " 'ayieeee': 732,\n",
       " 'ayieeeee': 733,\n",
       " 'aztec': 734,\n",
       " 'babs': 735,\n",
       " 'baby': 736,\n",
       " 'babysitting': 737,\n",
       " 'bachelor': 738,\n",
       " 'bachelorhood': 739,\n",
       " 'bachelors': 740,\n",
       " 'back': 741,\n",
       " 'backa': 742,\n",
       " 'backed': 743,\n",
       " 'background': 744,\n",
       " 'backlog': 745,\n",
       " 'backs': 746,\n",
       " 'backscratcher': 747,\n",
       " 'backside': 748,\n",
       " 'backup': 749,\n",
       " 'backward': 750,\n",
       " 'backwards': 751,\n",
       " 'backyard': 752,\n",
       " 'bacon': 753,\n",
       " 'bad': 754,\n",
       " 'badda': 755,\n",
       " 'baddest': 756,\n",
       " 'badge': 757,\n",
       " 'badger': 758,\n",
       " 'badly': 759,\n",
       " 'bag': 760,\n",
       " 'bagel': 761,\n",
       " 'bagged': 762,\n",
       " 'bagpipes': 763,\n",
       " 'bags': 764,\n",
       " 'bah': 765,\n",
       " 'bahamas': 766,\n",
       " 'bait': 767,\n",
       " 'baiting': 768,\n",
       " 'bake': 769,\n",
       " 'baked': 770,\n",
       " 'bakery': 771,\n",
       " 'baking': 772,\n",
       " 'balance': 773,\n",
       " 'balanced': 774,\n",
       " 'bald': 775,\n",
       " 'balding': 776,\n",
       " 'baling': 777,\n",
       " 'ball': 778,\n",
       " 'baller': 779,\n",
       " 'ballerina': 780,\n",
       " 'ballet': 781,\n",
       " 'balloon': 782,\n",
       " 'balloons': 783,\n",
       " 'balls': 784,\n",
       " 'baloney': 785,\n",
       " 'bam': 786,\n",
       " 'banana': 787,\n",
       " 'bananas': 788,\n",
       " 'band': 789,\n",
       " 'bandage': 790,\n",
       " 'bands': 791,\n",
       " 'bang': 792,\n",
       " 'bangor': 793,\n",
       " 'banjo': 794,\n",
       " 'bank': 795,\n",
       " 'banned': 796,\n",
       " 'banzai': 797,\n",
       " 'bap': 798,\n",
       " 'bar': 799,\n",
       " 'barbara': 800,\n",
       " 'barbarians': 801,\n",
       " 'barbaric': 802,\n",
       " 'barbecued': 803,\n",
       " 'barbecues': 804,\n",
       " 'barbecuing': 805,\n",
       " 'barbed': 806,\n",
       " 'barber': 807,\n",
       " 'barbershop': 808,\n",
       " 'barbie': 809,\n",
       " 'bare': 810,\n",
       " 'barely': 811,\n",
       " 'bares': 812,\n",
       " 'barfy': 813,\n",
       " 'bargains': 814,\n",
       " 'barge': 815,\n",
       " 'barista': 816,\n",
       " 'baritone': 817,\n",
       " 'bark': 818,\n",
       " 'barkbarkbarkbarkbarkbark': 819,\n",
       " 'barked': 820,\n",
       " 'barker': 821,\n",
       " 'barking': 822,\n",
       " 'barks': 823,\n",
       " 'barn': 824,\n",
       " 'barnard': 825,\n",
       " 'barney': 826,\n",
       " 'barns': 827,\n",
       " 'barnyard': 828,\n",
       " 'barren': 829,\n",
       " 'barrow': 830,\n",
       " 'bars': 831,\n",
       " 'bartholomew': 832,\n",
       " 'base': 833,\n",
       " 'based': 834,\n",
       " 'basement': 835,\n",
       " 'basic': 836,\n",
       " 'basicall': 837,\n",
       " 'basically': 838,\n",
       " 'basics': 839,\n",
       " 'basis': 840,\n",
       " 'bask': 841,\n",
       " 'basket': 842,\n",
       " 'basketball': 843,\n",
       " 'bat': 844,\n",
       " 'batch': 845,\n",
       " 'bath': 846,\n",
       " 'bathe': 847,\n",
       " 'bathing': 848,\n",
       " 'bathroom': 849,\n",
       " 'bathrooms': 850,\n",
       " 'baths': 851,\n",
       " 'bathtub': 852,\n",
       " 'baton': 853,\n",
       " 'bats': 854,\n",
       " 'batteries': 855,\n",
       " 'battering': 856,\n",
       " 'battery': 857,\n",
       " 'battle': 858,\n",
       " 'battles': 859,\n",
       " 'bayonne': 860,\n",
       " 'bazookas': 861,\n",
       " 'bbbbb': 862,\n",
       " 'bbbeeeeeee': 863,\n",
       " 'bcause': 864,\n",
       " 'be': 865,\n",
       " 'beach': 866,\n",
       " 'beaches': 867,\n",
       " 'beagle': 868,\n",
       " 'beak': 869,\n",
       " 'beaks': 870,\n",
       " 'beams': 871,\n",
       " 'bean': 872,\n",
       " 'beanpole': 873,\n",
       " 'beans': 874,\n",
       " 'bear': 875,\n",
       " 'beard': 876,\n",
       " 'bearded': 877,\n",
       " 'bearing': 878,\n",
       " 'bearings': 879,\n",
       " 'bears': 880,\n",
       " 'beast': 881,\n",
       " 'beasts': 882,\n",
       " 'beat': 883,\n",
       " 'beaten': 884,\n",
       " 'beaters': 885,\n",
       " 'beating': 886,\n",
       " 'beats': 887,\n",
       " 'beau': 888,\n",
       " 'beauchamp': 889,\n",
       " 'beautiful': 890,\n",
       " 'beauty': 891,\n",
       " 'beaver': 892,\n",
       " 'becaaause': 893,\n",
       " 'becaaauuuuse': 894,\n",
       " 'became': 895,\n",
       " 'becaus': 896,\n",
       " 'because': 897,\n",
       " 'beck': 898,\n",
       " 'becky': 899,\n",
       " 'become': 900,\n",
       " 'becomes': 901,\n",
       " 'becoming': 902,\n",
       " 'bed': 903,\n",
       " 'bedroom': 904,\n",
       " 'beds': 905,\n",
       " 'bedtime': 906,\n",
       " 'bee': 907,\n",
       " 'beedle': 908,\n",
       " 'beeeautiful': 909,\n",
       " 'beeep': 910,\n",
       " 'beef': 911,\n",
       " 'beehive': 912,\n",
       " 'been': 913,\n",
       " 'beep': 914,\n",
       " 'beepbip': 915,\n",
       " 'beeper': 916,\n",
       " 'beer': 917,\n",
       " 'bees': 918,\n",
       " 'beethoven': 919,\n",
       " 'beetle': 920,\n",
       " 'beetles': 921,\n",
       " 'befor': 922,\n",
       " 'before': 923,\n",
       " 'beg': 924,\n",
       " 'began': 925,\n",
       " 'beggar': 926,\n",
       " 'begging': 927,\n",
       " 'begin': 928,\n",
       " 'beginning': 929,\n",
       " 'begins': 930,\n",
       " 'begun': 931,\n",
       " 'behalf': 932,\n",
       " 'behave': 933,\n",
       " 'behaving': 934,\n",
       " 'behavior': 935,\n",
       " 'behaviors': 936,\n",
       " 'behind': 937,\n",
       " 'behinder': 938,\n",
       " 'behold': 939,\n",
       " 'bein': 940,\n",
       " 'being': 941,\n",
       " 'beings': 942,\n",
       " 'beint': 943,\n",
       " 'belach': 944,\n",
       " 'belch': 945,\n",
       " 'belched': 946,\n",
       " 'belching': 947,\n",
       " 'belief': 948,\n",
       " 'beliefs': 949,\n",
       " 'believable': 950,\n",
       " 'believe': 951,\n",
       " 'believed': 952,\n",
       " 'belinda': 953,\n",
       " 'bell': 954,\n",
       " 'bells': 955,\n",
       " 'belly': 956,\n",
       " 'bellybutton': 957,\n",
       " 'belong': 958,\n",
       " 'belongs': 959,\n",
       " 'below': 960,\n",
       " 'belt': 961,\n",
       " 'belts': 962,\n",
       " 'beluieve': 963,\n",
       " 'bend': 964,\n",
       " 'beneath': 965,\n",
       " 'benefit': 966,\n",
       " 'benefits': 967,\n",
       " 'benevolent': 968,\n",
       " 'benjamin': 969,\n",
       " 'benny': 970,\n",
       " 'bent': 971,\n",
       " 'berle': 972,\n",
       " 'bermuda': 973,\n",
       " 'bernice': 974,\n",
       " 'bernie': 975,\n",
       " 'berries': 976,\n",
       " 'berry': 977,\n",
       " 'bertha': 978,\n",
       " 'bes': 979,\n",
       " 'beside': 980,\n",
       " 'besides': 981,\n",
       " 'bessie': 982,\n",
       " 'best': 983,\n",
       " 'bests': 984,\n",
       " 'bet': 985,\n",
       " 'betcha': 986,\n",
       " 'beth': 987,\n",
       " 'bets': 988,\n",
       " 'betsy': 989,\n",
       " 'better': 990,\n",
       " 'betting': 991,\n",
       " 'betty': 992,\n",
       " 'between': 993,\n",
       " 'beverage': 994,\n",
       " 'bewar': 995,\n",
       " 'beware': 996,\n",
       " 'bewitching': 997,\n",
       " 'biased': 998,\n",
       " 'bib': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words:  195203\n",
      "Total Vocab:  11613\n"
     ]
    }
   ],
   "source": [
    "n_words = word_count\n",
    "n_vocab = len(words)\n",
    "print (\"Total Words: \", n_words)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'there',\n",
       " 'i',\n",
       " 'jon',\n",
       " 'arbuckle',\n",
       " 'i',\n",
       " 'a',\n",
       " 'cartoonist',\n",
       " 'and',\n",
       " 'this',\n",
       " 'is',\n",
       " 'my',\n",
       " 'cat',\n",
       " 'garfield',\n",
       " '-',\n",
       " 'hi',\n",
       " 'there',\n",
       " 'i',\n",
       " 'garfield',\n",
       " 'i',\n",
       " 'a',\n",
       " 'cat',\n",
       " 'and',\n",
       " 'this',\n",
       " 'is',\n",
       " 'my',\n",
       " 'cartoonist',\n",
       " 'jon',\n",
       " '-',\n",
       " 'our',\n",
       " 'only',\n",
       " 'thought',\n",
       " 'is',\n",
       " 'to',\n",
       " 'entertain',\n",
       " 'you',\n",
       " 'feed',\n",
       " 'me',\n",
       " 'happy',\n",
       " 'birthday',\n",
       " 'garfield',\n",
       " 'i',\n",
       " 'have',\n",
       " 'a',\n",
       " 'surprise',\n",
       " 'for',\n",
       " 'you',\n",
       " '-',\n",
       " 'a',\n",
       " 'rubber',\n",
       " 'mousey',\n",
       " '-',\n",
       " 'could',\n",
       " 've',\n",
       " 'used',\n",
       " 'a',\n",
       " 'little',\n",
       " 'salt',\n",
       " 'a',\n",
       " 'mouse',\n",
       " 'get',\n",
       " 'it',\n",
       " '-',\n",
       " 'garfield',\n",
       " 'you',\n",
       " 'didn',\n",
       " 'even',\n",
       " 'try',\n",
       " '-',\n",
       " 'show',\n",
       " 'me',\n",
       " 'a',\n",
       " 'good',\n",
       " 'mouser',\n",
       " 'and',\n",
       " 'i',\n",
       " 'll',\n",
       " 'show',\n",
       " 'you',\n",
       " 'a',\n",
       " 'cat',\n",
       " 'with',\n",
       " 'bad',\n",
       " 'breath',\n",
       " 'here',\n",
       " 'garfield',\n",
       " 'beg',\n",
       " '-',\n",
       " 'eeyouch',\n",
       " '-',\n",
       " 'groveling',\n",
       " 'is',\n",
       " 'not',\n",
       " 'one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'strong',\n",
       " 'suits',\n",
       " 'all',\n",
       " 'i',\n",
       " 'ever',\n",
       " 'do',\n",
       " 'is',\n",
       " 'eat',\n",
       " 'and',\n",
       " 'sleep',\n",
       " 'eat',\n",
       " 'and',\n",
       " 'sleep',\n",
       " 'eat',\n",
       " 'and',\n",
       " 'sleep',\n",
       " '-',\n",
       " 'there',\n",
       " 'must',\n",
       " 'be',\n",
       " 'more',\n",
       " 'to',\n",
       " 'a',\n",
       " 'cat',\n",
       " 'life',\n",
       " 'than',\n",
       " 'that',\n",
       " '-',\n",
       " 'but',\n",
       " 'i',\n",
       " 'hope',\n",
       " 'not',\n",
       " 'itch',\n",
       " 'scratch',\n",
       " 'scratch',\n",
       " '-',\n",
       " 'scratch',\n",
       " 'scratch',\n",
       " 'scratch',\n",
       " 'scratch',\n",
       " 'itch',\n",
       " 'scratch',\n",
       " 'scratch',\n",
       " 'scratch',\n",
       " 'scratch',\n",
       " '-',\n",
       " 'aarrrgh',\n",
       " 'sniff',\n",
       " '-',\n",
       " 'cat',\n",
       " 'food',\n",
       " '-',\n",
       " 'the',\n",
       " 'bouquet',\n",
       " 'leaves',\n",
       " 'something',\n",
       " 'to',\n",
       " 'be',\n",
       " 'desired',\n",
       " 'i',\n",
       " 'getting',\n",
       " 'lazy',\n",
       " 'it',\n",
       " 'would',\n",
       " 'do',\n",
       " 'me',\n",
       " 'good',\n",
       " 'to',\n",
       " 'get',\n",
       " 'some',\n",
       " 'exercise',\n",
       " '-',\n",
       " 'yawn',\n",
       " '-',\n",
       " 'much',\n",
       " 'better',\n",
       " 'i',\n",
       " 'going',\n",
       " 'to',\n",
       " 'take',\n",
       " 'an',\n",
       " 'active',\n",
       " 'part',\n",
       " 'in',\n",
       " 'energy',\n",
       " 'conservation',\n",
       " '-',\n",
       " 'get',\n",
       " 'on',\n",
       " 'your',\n",
       " 'mark',\n",
       " 'get',\n",
       " 'set',\n",
       " '-',\n",
       " 'conserve',\n",
       " 'i',\n",
       " 'just',\n",
       " 'your',\n",
       " 'average',\n",
       " 'ordinary',\n",
       " 'cat',\n",
       " '-',\n",
       " 'for',\n",
       " 'instance',\n",
       " 'i',\n",
       " 'crazy',\n",
       " 'about',\n",
       " 'nature',\n",
       " 'most',\n",
       " 'perfect',\n",
       " 'food',\n",
       " '-',\n",
       " 'lasagna',\n",
       " 'yawn',\n",
       " '-',\n",
       " 'crick',\n",
       " '-',\n",
       " 'hello',\n",
       " 'doctor',\n",
       " 'my',\n",
       " 'cat',\n",
       " 'stuck',\n",
       " 'in',\n",
       " 'a',\n",
       " 'stretch',\n",
       " 'slurp',\n",
       " 'munch',\n",
       " 'smack',\n",
       " '-',\n",
       " 'garfield',\n",
       " 'you',\n",
       " 're',\n",
       " 'a',\n",
       " 'fat',\n",
       " 'arrogant',\n",
       " 'lazy',\n",
       " 'pig',\n",
       " '-',\n",
       " 'well',\n",
       " 'excuuuuuuse',\n",
       " 'me',\n",
       " 'squirt',\n",
       " '-',\n",
       " 'chunk',\n",
       " 'chunk',\n",
       " 'chunk',\n",
       " 'chunk',\n",
       " 'chunk',\n",
       " 'chunk',\n",
       " 'chunk',\n",
       " 'chunk',\n",
       " '-',\n",
       " 'garfield',\n",
       " 'you',\n",
       " 'should',\n",
       " 'really',\n",
       " 'learn',\n",
       " 'to',\n",
       " 'control',\n",
       " 'your',\n",
       " 'temper',\n",
       " 'scratch',\n",
       " 'scratch',\n",
       " 'scratch',\n",
       " 'scratch',\n",
       " '-',\n",
       " 'oops',\n",
       " 'i',\n",
       " 'got',\n",
       " 'a',\n",
       " 'scratch',\n",
       " 'on',\n",
       " 'jon',\n",
       " 'favorite',\n",
       " 'chair',\n",
       " '-',\n",
       " 'maybe',\n",
       " 'he',\n",
       " 'won',\n",
       " 'notice',\n",
       " 'is',\n",
       " 'that',\n",
       " 'all',\n",
       " 'you',\n",
       " 'have',\n",
       " 'the',\n",
       " 'one',\n",
       " 'suitcase',\n",
       " 'not',\n",
       " 'exactly',\n",
       " '-',\n",
       " 'here',\n",
       " 'boy',\n",
       " '-',\n",
       " 'oh',\n",
       " 'lawsey',\n",
       " 'lawsey',\n",
       " 'lawsey',\n",
       " 'what',\n",
       " 'your',\n",
       " 'dog',\n",
       " 'name',\n",
       " 'odie',\n",
       " '-',\n",
       " 'odie',\n",
       " 'a',\n",
       " 'dog',\n",
       " 'named',\n",
       " 'odie',\n",
       " '-',\n",
       " 'a',\n",
       " 'blimp',\n",
       " 'named',\n",
       " 'hindenburg',\n",
       " 'a',\n",
       " 'ship',\n",
       " 'named',\n",
       " 'titanic',\n",
       " 'a',\n",
       " 'car',\n",
       " 'named',\n",
       " 'edsel',\n",
       " 'a',\n",
       " 'fresh',\n",
       " 'woof',\n",
       " '-',\n",
       " 'bark',\n",
       " '-',\n",
       " 'yip',\n",
       " 'yip',\n",
       " 'yip',\n",
       " 'yip',\n",
       " 'odie',\n",
       " 'look',\n",
       " 'what',\n",
       " 'you',\n",
       " 'did',\n",
       " 'on',\n",
       " 'the',\n",
       " 'floor',\n",
       " '-',\n",
       " 'yip',\n",
       " 'yip',\n",
       " 'yip',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'whap',\n",
       " 'whap',\n",
       " 'whap',\n",
       " '-',\n",
       " 'they',\n",
       " 'should',\n",
       " 've',\n",
       " 'named',\n",
       " 'him',\n",
       " 'spot',\n",
       " 'heh',\n",
       " 'heh',\n",
       " 'heh',\n",
       " 'splash',\n",
       " 'splash',\n",
       " 'splash',\n",
       " '-',\n",
       " 'cats',\n",
       " 'just',\n",
       " 'love',\n",
       " 'to',\n",
       " 'play',\n",
       " 'with',\n",
       " 'water',\n",
       " '-',\n",
       " 'whew',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'i',\n",
       " 'never',\n",
       " 'find',\n",
       " 'jon',\n",
       " 'watch',\n",
       " 'dab',\n",
       " 'dab',\n",
       " 'dab',\n",
       " 'dab',\n",
       " '-',\n",
       " 'splash',\n",
       " 'splash',\n",
       " 'splash',\n",
       " 'splash',\n",
       " 'splash',\n",
       " '-',\n",
       " 'my',\n",
       " 'chicken',\n",
       " 'soup',\n",
       " 'the',\n",
       " 'devil',\n",
       " 'made',\n",
       " 'me',\n",
       " 'do',\n",
       " 'it',\n",
       " 'munch',\n",
       " 'munch',\n",
       " 'munch',\n",
       " '-',\n",
       " 'punt',\n",
       " '-',\n",
       " 'gotta',\n",
       " 'keep',\n",
       " 'my',\n",
       " 'strength',\n",
       " 'up',\n",
       " 'garfield',\n",
       " 'as',\n",
       " 'of',\n",
       " 'this',\n",
       " 'minute',\n",
       " 'i',\n",
       " 'putting',\n",
       " 'you',\n",
       " 'on',\n",
       " 'a',\n",
       " 'diet',\n",
       " '-',\n",
       " 'garfield',\n",
       " '-',\n",
       " 'i',\n",
       " 'think',\n",
       " 'i',\n",
       " 'snapped',\n",
       " 'his',\n",
       " 'mind',\n",
       " 'so',\n",
       " 'i',\n",
       " 'on',\n",
       " 'a',\n",
       " 'diet',\n",
       " 'big',\n",
       " 'deal',\n",
       " '-',\n",
       " 'you',\n",
       " 'know',\n",
       " 'what',\n",
       " 'a',\n",
       " 'diet',\n",
       " 'is',\n",
       " 'don',\n",
       " 'you',\n",
       " '-',\n",
       " 'it',\n",
       " 'die',\n",
       " 'with',\n",
       " 'a',\n",
       " 'that',\n",
       " 'what',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'diet',\n",
       " 'jon',\n",
       " 'has',\n",
       " 'me',\n",
       " 'on',\n",
       " 'a',\n",
       " 'diet',\n",
       " '-',\n",
       " 'poomp',\n",
       " '-',\n",
       " 'when',\n",
       " 'the',\n",
       " 'lasagna',\n",
       " 'content',\n",
       " 'in',\n",
       " 'my',\n",
       " 'blood',\n",
       " 'gets',\n",
       " 'low',\n",
       " 'i',\n",
       " 'get',\n",
       " 'mean',\n",
       " 'let',\n",
       " 'see',\n",
       " 'see',\n",
       " 'how',\n",
       " 'well',\n",
       " 'you',\n",
       " 've',\n",
       " 'done',\n",
       " 'your',\n",
       " 'diet',\n",
       " 'this',\n",
       " 'week',\n",
       " 'garfield',\n",
       " '-',\n",
       " 'now',\n",
       " 'where',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " 'scale',\n",
       " '-',\n",
       " 'i',\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'it',\n",
       " 'labor',\n",
       " 'day',\n",
       " 'shmabor',\n",
       " 'day',\n",
       " 'what',\n",
       " 'a',\n",
       " 'dumb',\n",
       " 'day',\n",
       " '-',\n",
       " 'to',\n",
       " 'hire',\n",
       " 'some',\n",
       " 'jerk',\n",
       " 'then',\n",
       " 'send',\n",
       " 'him',\n",
       " 'away',\n",
       " '-',\n",
       " 'to',\n",
       " 'celebrate',\n",
       " 'work',\n",
       " 'by',\n",
       " 'playing',\n",
       " 'all',\n",
       " 'day',\n",
       " 'and',\n",
       " 'that',\n",
       " 'all',\n",
       " 'for',\n",
       " 'mystery',\n",
       " 'theater',\n",
       " 'good',\n",
       " 'night',\n",
       " '-',\n",
       " 'click',\n",
       " '-',\n",
       " 'click',\n",
       " 'garfield',\n",
       " 'cut',\n",
       " 'that',\n",
       " 'out',\n",
       " 'what',\n",
       " 're',\n",
       " 'you',\n",
       " 'doing',\n",
       " 'tonight',\n",
       " 'lyman',\n",
       " 'i',\n",
       " 'gonna',\n",
       " 'catch',\n",
       " 'the',\n",
       " 'new',\n",
       " 'flick',\n",
       " 'down',\n",
       " 'at',\n",
       " 'the',\n",
       " 'bijou',\n",
       " '-',\n",
       " 'it',\n",
       " 'about',\n",
       " 'this',\n",
       " 'kid',\n",
       " 'who',\n",
       " 'puts',\n",
       " 'a',\n",
       " 'tack',\n",
       " 'in',\n",
       " 'his',\n",
       " 'teacher',\n",
       " 'chair',\n",
       " 'and',\n",
       " 'she',\n",
       " 'sits',\n",
       " 'on',\n",
       " 'it',\n",
       " '-',\n",
       " 'not',\n",
       " 'much',\n",
       " 'of',\n",
       " 'a',\n",
       " 'plot',\n",
       " 'i',\n",
       " 'suppose',\n",
       " 'not',\n",
       " 'but',\n",
       " 'i',\n",
       " 'still',\n",
       " 'enjoy',\n",
       " 'the',\n",
       " 'movies',\n",
       " 'where',\n",
       " 'the',\n",
       " 'purrrr',\n",
       " '-',\n",
       " 'purrr',\n",
       " '-',\n",
       " 'have',\n",
       " 'some',\n",
       " 'lasagna',\n",
       " 'garfield',\n",
       " 'purrr',\n",
       " 'darn',\n",
       " 'bugs',\n",
       " 'buzzzzz',\n",
       " '-',\n",
       " 'swat',\n",
       " 'splat',\n",
       " '-',\n",
       " 'thanks',\n",
       " 'i',\n",
       " 'needed',\n",
       " 'that',\n",
       " 'i',\n",
       " 'hate',\n",
       " 'summer',\n",
       " '-',\n",
       " 'the',\n",
       " 'unbearable',\n",
       " 'heat',\n",
       " 'sticky',\n",
       " 'car',\n",
       " 'seats',\n",
       " 'hay',\n",
       " 'fever',\n",
       " 'season',\n",
       " 'and',\n",
       " 'scorched',\n",
       " 'lawns',\n",
       " '-',\n",
       " 'not',\n",
       " 'to',\n",
       " 'mention',\n",
       " 'curdled',\n",
       " 'kitty',\n",
       " 'munchies',\n",
       " 'oh',\n",
       " 'boy',\n",
       " 'at',\n",
       " 'last',\n",
       " 'college',\n",
       " 'football',\n",
       " 'season',\n",
       " '-',\n",
       " 'i',\n",
       " 'would',\n",
       " 'have',\n",
       " 'played',\n",
       " 'college',\n",
       " 'football',\n",
       " 'had',\n",
       " 'it',\n",
       " 'not',\n",
       " 'been',\n",
       " 'for',\n",
       " 'my',\n",
       " 'beliefs',\n",
       " '-',\n",
       " 'i',\n",
       " 'don',\n",
       " 'believe',\n",
       " 'in',\n",
       " 'bleeding',\n",
       " 'on',\n",
       " 'saturday',\n",
       " 'how',\n",
       " 'would',\n",
       " 'you',\n",
       " 'like',\n",
       " 'to',\n",
       " 'be',\n",
       " 'unnecessarily',\n",
       " 'roughed',\n",
       " 'all',\n",
       " 'dogs',\n",
       " 'should',\n",
       " 'be',\n",
       " 'banned',\n",
       " 'from',\n",
       " 'our',\n",
       " 'country',\n",
       " '-',\n",
       " 'they',\n",
       " 'are',\n",
       " 'noisy',\n",
       " 'silly',\n",
       " 'sloppy',\n",
       " 'rude',\n",
       " '-',\n",
       " 'and',\n",
       " 'they',\n",
       " 're',\n",
       " 'rusting',\n",
       " 'our',\n",
       " 'nation',\n",
       " 'fire',\n",
       " 'hydrants',\n",
       " 'bbbbb',\n",
       " '-',\n",
       " 'bark',\n",
       " '-',\n",
       " 'i',\n",
       " 'hate',\n",
       " 'to',\n",
       " 'see',\n",
       " 'that',\n",
       " 'sucker',\n",
       " 'bite',\n",
       " 'garfield',\n",
       " '-',\n",
       " 'bark',\n",
       " '-',\n",
       " 'if',\n",
       " 'god',\n",
       " 'had',\n",
       " 'intended',\n",
       " 'for',\n",
       " 'dogs',\n",
       " 'to',\n",
       " 'bark',\n",
       " 'he',\n",
       " 'would',\n",
       " 'have',\n",
       " 'given',\n",
       " 'them',\n",
       " 'roots',\n",
       " 'and',\n",
       " 'leaves',\n",
       " 'biff',\n",
       " '-',\n",
       " 'bop',\n",
       " '-',\n",
       " 'smack',\n",
       " 'poke',\n",
       " 'garfield',\n",
       " 'one',\n",
       " 'odie',\n",
       " 'one',\n",
       " 'boing',\n",
       " '-',\n",
       " 'rrrr',\n",
       " '-',\n",
       " 'i',\n",
       " 'hate',\n",
       " 'mondays',\n",
       " 'i',\n",
       " 'wonder',\n",
       " 'if',\n",
       " 'i',\n",
       " 'should',\n",
       " 'pick',\n",
       " 'up',\n",
       " 'anything',\n",
       " 'for',\n",
       " 'garfield',\n",
       " 'from',\n",
       " 'the',\n",
       " 'pet',\n",
       " 'store',\n",
       " 'how',\n",
       " 'about',\n",
       " 'a',\n",
       " 'scratching',\n",
       " 'post',\n",
       " '-',\n",
       " 'good',\n",
       " 'idea',\n",
       " 'i',\n",
       " 'll',\n",
       " 'get',\n",
       " 'him',\n",
       " 'one',\n",
       " '-',\n",
       " 'bless',\n",
       " 'you',\n",
       " 'yawn',\n",
       " '-',\n",
       " 'that',\n",
       " 'floor',\n",
       " 'sure',\n",
       " 'looks',\n",
       " 'cold',\n",
       " 'this',\n",
       " 'morning',\n",
       " '-',\n",
       " 'better',\n",
       " 'not',\n",
       " 'risk',\n",
       " 'it',\n",
       " 'i',\n",
       " 'not',\n",
       " 'getting',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'bed',\n",
       " 'if',\n",
       " 'the',\n",
       " 'floor',\n",
       " 'is',\n",
       " 'cold',\n",
       " '-',\n",
       " 'it',\n",
       " 'freezing',\n",
       " '-',\n",
       " 'good',\n",
       " 'zzzzz',\n",
       " '-',\n",
       " 'bark',\n",
       " '-',\n",
       " 'now',\n",
       " 'that',\n",
       " 'i',\n",
       " 'up',\n",
       " 'i',\n",
       " 'might',\n",
       " 'as',\n",
       " 'well',\n",
       " 'have',\n",
       " 'breakfast',\n",
       " 'water',\n",
       " 'water',\n",
       " 'water',\n",
       " '-',\n",
       " 'pat',\n",
       " 'pat',\n",
       " 'pat',\n",
       " '-',\n",
       " 'what',\n",
       " 'the',\n",
       " 'use',\n",
       " 'garfield',\n",
       " 'i',\n",
       " 'back',\n",
       " 'from',\n",
       " 'the',\n",
       " 'store',\n",
       " '-',\n",
       " 'we',\n",
       " 're',\n",
       " 'having',\n",
       " 'a',\n",
       " 'cookout',\n",
       " 'tonight',\n",
       " 'i',\n",
       " 'got',\n",
       " 'steak',\n",
       " 'and',\n",
       " 'corn',\n",
       " 'and',\n",
       " '-',\n",
       " 'and',\n",
       " 'you',\n",
       " 'just',\n",
       " 'ate',\n",
       " 'the',\n",
       " 'briquettes',\n",
       " 'garfield',\n",
       " 'i',\n",
       " 'going',\n",
       " 'to',\n",
       " 'have',\n",
       " 'you',\n",
       " 'declawed',\n",
       " '-',\n",
       " 'take',\n",
       " 'an',\n",
       " 'arm',\n",
       " 'take',\n",
       " 'a',\n",
       " 'leg',\n",
       " 'but',\n",
       " 'spare',\n",
       " 'my',\n",
       " 'claws',\n",
       " '-',\n",
       " 'you',\n",
       " 're',\n",
       " 'going',\n",
       " 'to',\n",
       " 'be',\n",
       " 'declawed',\n",
       " 'and',\n",
       " 'that',\n",
       " 'it',\n",
       " 'now',\n",
       " 'get',\n",
       " 'your',\n",
       " 'head',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'oven',\n",
       " 'jon',\n",
       " 'gonna',\n",
       " 'have',\n",
       " 'me',\n",
       " 'declawed',\n",
       " '-',\n",
       " 'what',\n",
       " 'a',\n",
       " 'frightening',\n",
       " 'thought',\n",
       " '-',\n",
       " 'going',\n",
       " 'through',\n",
       " 'life',\n",
       " 'unarmed',\n",
       " 'i',\n",
       " 'took',\n",
       " 'garfield',\n",
       " 'to',\n",
       " 'the',\n",
       " 'vet',\n",
       " 'to',\n",
       " 'be',\n",
       " 'declawed',\n",
       " '-',\n",
       " 'they',\n",
       " 're',\n",
       " 'removing',\n",
       " 'his',\n",
       " 'stitches',\n",
       " 'next',\n",
       " 'thursday',\n",
       " '-',\n",
       " 'poor',\n",
       " 'garfield',\n",
       " 'who',\n",
       " 'talking',\n",
       " 'about',\n",
       " 'garfield',\n",
       " 'i',\n",
       " 'sorry',\n",
       " 'i',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'have',\n",
       " 'you',\n",
       " 'declawed',\n",
       " 'garfield',\n",
       " '-',\n",
       " 'i',\n",
       " 'love',\n",
       " 'you',\n",
       " 'just',\n",
       " 'the',\n",
       " 'way',\n",
       " 'you',\n",
       " 'are',\n",
       " 'claws',\n",
       " 'and',\n",
       " 'all',\n",
       " '-',\n",
       " 'someday',\n",
       " 'somehow',\n",
       " 'when',\n",
       " 'you',\n",
       " 're',\n",
       " 'least',\n",
       " 'expecting',\n",
       " 'it',\n",
       " 'i',\n",
       " 'going',\n",
       " 'to',\n",
       " 'shred',\n",
       " 'your',\n",
       " 'bedroom',\n",
       " 'suite',\n",
       " 'oh',\n",
       " 'boy',\n",
       " 'my',\n",
       " 'bachelor',\n",
       " 'magazine',\n",
       " '-',\n",
       " 'i',\n",
       " 'wonder',\n",
       " 'who',\n",
       " 'the',\n",
       " 'centerfold',\n",
       " 'is',\n",
       " 'elke',\n",
       " 'farrah',\n",
       " '-',\n",
       " 'almira',\n",
       " 'the',\n",
       " 'amazon',\n",
       " 'bark',\n",
       " '-',\n",
       " 'odie',\n",
       " 'cut',\n",
       " 'that',\n",
       " 'out',\n",
       " '-',\n",
       " 'stick',\n",
       " 'with',\n",
       " 'me',\n",
       " 'kid',\n",
       " 'we',\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195203"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  195173\n"
     ]
    }
   ],
   "source": [
    "...\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 30\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_words - seq_length, 1):\n",
    "\tseq_in = all_word_list[i:i + seq_length]\n",
    "\tseq_out = all_word_list[i + seq_length]\n",
    "\tdataX.append([word_to_int[word] for word in seq_in])\n",
    "\tdataY.append(word_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_nodes = int(2/3 * (max_phrase_length * len(word_set)))\n",
    "# hidden_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # define the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(y.shape[1], activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = len(words)\n",
    "# # The embedding dimension\n",
    "# embedding_dim = 256\n",
    "\n",
    "# # Number of RNN units\n",
    "# rnn_units = 1024\n",
    "\n",
    "# batch_size = 64\n",
    "\n",
    "# # Buffer size to shuffle the dataset\n",
    "# # (TF data is designed to work with possibly infinite sequences,\n",
    "# # so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# # it maintains a buffer in which it shuffles elements).\n",
    "# BUFFER_SIZE = 10000\n",
    "\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "#                               batch_input_shape=[batch_size, None]),\n",
    "#     tf.keras.layers.GRU(rnn_units,\n",
    "#                         return_sequences=True,\n",
    "#                         stateful=True,\n",
    "#                         recurrent_initializer='glorot_uniform'),\n",
    "#     tf.keras.layers.Dense(vocab_size)\n",
    "#   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "# filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "# filepath=\"weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "filepath=\"try.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 195173 samples\n",
      "Epoch 1/80\n",
      " 63648/195173 [========>.....................] - ETA: 20:27 - loss: 6.5569 - accuracy: 0.0841\n",
      "Epoch 00001: loss improved from inf to 6.55362, saving model to try.hdf5\n",
      " 63648/195173 [========>.....................] - ETA: 20:27 - loss: 6.5569 - accuracy: 0.0841"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-b786cc53c137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=80, batch_size=32, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # load the network weights\n",
    "filename = \"weights/try.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_word = dict((i, w) for i, w in enumerate(words))\n",
    "int_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "# generate characters\n",
    "print(\"\\\"\", ' '.join([int_to_word[value] for value in pattern]), \"\\\"\")\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_word[index]\n",
    "    seq_in = [int_to_word[value] for value in pattern]\n",
    "    print(result, end=\" \", flush=True)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for value in pattern:\n",
    "#     print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
